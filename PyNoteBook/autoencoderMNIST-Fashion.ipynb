{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder - Dimensionality Reduction of MNIST FASHION DataSet\n",
    "Compare the lossy ratio between multiple latent spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q imageio pydot tensorflow-gpu==2.9.1 keras matplotlib graphviz moviepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all Modules and Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable float16 bit for improved performance.\n",
    "        mixed_precision.set_global_policy('mixed_float16')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFashion():\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "    TrainX = np.concatenate((train_images, test_images))\n",
    "    # Normalize byte [0,255] -> [0,1]\n",
    "    TrainX = (TrainX / 255.0)\n",
    "\n",
    "    return TrainX\n",
    "\n",
    "    #\n",
    "def loadMNIST():\n",
    "    (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "    # Normalize byte [0,255] -> [0,1]\n",
    "    train_X = train_X / 255.0\n",
    "    test_X = test_X / 255.0\n",
    "\n",
    "    return np.concatenate((train_X, test_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 192\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "fashionX = loadDataFashion()\n",
    "MnistX = loadMNIST()\n",
    "\n",
    "trainX = np.concatenate((fashionX, MnistX)).astype(dtype='float16')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "nrImage = 4 * 8\n",
    "for index, image in enumerate(trainX[0:nrImage]):\n",
    "    plt.subplot(4, 8, (index + 1))\n",
    "\n",
    "    plt.imshow(X=((image + 1.0) / 2.0).astype(dtype='float32'), cmap=plt.cm.gray, aspect='auto')\n",
    "    plt.axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dimensionality Reduction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_constructor(hp, latent_space, image_size):\n",
    "\n",
    "    class Autoencoder(keras.Model):\n",
    "        def __init__(self, hp, **kwargs):\n",
    "            super(Autoencoder, self).__init__(**kwargs)\n",
    "\n",
    "            kernel_init = hp.Choice('kernel_initializer', ['uniform', 'lecun_uniform', 'normal', 'zero',\n",
    "                                                           'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'])\n",
    "            kernel_activation = hp.Choice('kernel_activation', ['relu', 'sigmoid', 'softmax', 'tanh'])\n",
    "\n",
    "            number_layers = hp.Int(\n",
    "                'number_layers', min_value=0, max_value=4, step=1)\n",
    "\n",
    "\n",
    "            encoder_dense_layers = [layers.Dense(256 / (2 ** i), activation=kernel_activation, kernel_initializer=kernel_init)\n",
    "                                    for i in range(0, number_layers + 1)]\n",
    "\n",
    "            self.encoder = tf.keras.Sequential()\n",
    "            self.encoder.add(layers.Flatten())\n",
    "\n",
    "            for layer in encoder_dense_layers:\n",
    "                self.encoder.add(layer)\n",
    "\n",
    "            self.encoder.add(layers.Dense(latent_space, activation=kernel_activation, kernel_initializer=kernel_init, name=\"latent space\"))\n",
    "\n",
    "            decoder_dense_layers = [layers.Dense(256 / (2 ** i), activation=kernel_activation, kernel_initializer=kernel_init)\n",
    "                                    for i in range(0, number_layers + 1)]\n",
    "\n",
    "            self.decoder = tf.keras.Sequential()\n",
    "            for layer in reversed(decoder_dense_layers):\n",
    "                self.decoder.add(layer)\n",
    "\n",
    "            self.decoder.add(layers.Dense(np.prod(image_size), activation='sigmoid', kernel_initializer=kernel_init))\n",
    "            self.decoder.add(layers.Reshape(image_size))\n",
    "\n",
    "        def call(self, x):\n",
    "            encoded = self.encoder(x)\n",
    "            decoded = self.decoder(encoded)\n",
    "            return decoded\n",
    "\n",
    "        def getEncoder(self):\n",
    "            return self.encoder\n",
    "\n",
    "        def getDecoder(self):\n",
    "            return self.decoder\n",
    "\n",
    "        def getModel(self):\n",
    "            ae_input = layers.Input(shape=image_size, name=\"AE_input\")\n",
    "            ae_encoder_output = self.getEncoder()(ae_input)\n",
    "            ae_decoder_output = self.getDecoder()(ae_encoder_output)\n",
    "\n",
    "            return keras.Model(inputs=ae_input, outputs=ae_decoder_output)\n",
    "\n",
    "        def compile(self, **kwargs):\n",
    "            super(Autoencoder, self).compile(**kwargs)\n",
    "\n",
    "        def summary(self, **kwargs):\n",
    "            super(Autoencoder, self).summary(**kwargs)\n",
    "            self.encoder.summary()\n",
    "\n",
    "    autoencoder = Autoencoder(hp)\n",
    "    hp_optimizer = hp.Choice('optimizer', ['sgd', 'adam', 'rmsprop'])\n",
    "\n",
    "    autoencoder.compile(optimizer=hp_optimizer, loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter\n",
    "Find the best model out of all the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_shape = trainX[0].shape\n",
    "print('X_train: ' + str(image_shape))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, X_train, test_size=0.12, random_state=42)\n",
    "\n",
    "latent_spaces = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "ae_models = []\n",
    "\n",
    "for latent_space in latent_spaces:\n",
    "\n",
    "    def hyperparamter_model_builder(hp):\n",
    "        model = model_constructor(hp, latent_space, image_shape)\n",
    "        return model\n",
    "\n",
    "    tuner = kt.Hyperband(hyperparamter_model_builder,\n",
    "                         objective='val_accuracy',\n",
    "                         max_epochs=16,\n",
    "                         factor=3,\n",
    "                         directory='cache',\n",
    "                         project_name=str.format('MNIST AutoEncoder Reconstruct L{0} - {1}', latent_space, \"Compression\"))\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=4)\n",
    "    tuner.search(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val),\n",
    "                 callbacks=[stop_early], verbose=1)\n",
    "\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_models = tuner.get_best_models(4)\n",
    "\n",
    "    autoencoder_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "    ae_models.append(autoencoder_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResult(model, batchImage, maxNumImages=6):\n",
    "\n",
    "    batch_iter = iter(batchImage)\n",
    "    image_batch, _ = next(batch_iter)\n",
    "\n",
    "    output = model.predict(batchImage)\n",
    "    nrElements = min(len(output), maxNumImages)\n",
    "\n",
    "    fig = plt.figure(figsize=(maxNumImages * 2, 2 * 2))\n",
    "    for i in range(nrElements):\n",
    "        trainImage = image\n",
    "\n",
    "        ax = plt.subplot(2, maxNumImages, i + 1)\n",
    "        plt.imshow((batchImage[i].astype(dtype='float32')), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        ax = plt.subplot(2, maxNumImages, maxNumImages + i + 1)\n",
    "        plt.imshow((output[i].astype(dtype='float32')), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "\n",
    "class save_images(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, latent_space, trainData, **kwargs):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__(**kwargs)\n",
    "        self.trainSet = trainData[0:20]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        fig = showResult(self.model, self.trainSet)\n",
    "        fig.savefig(\"MNISTCompression{0}.png\".format(epoch))\n",
    "        fig = showResult(self.model, self.trainSet, 12)\n",
    "        fig.savefig(\"MNISTCompressionBig{0}.png\".format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = []\n",
    "\n",
    "for latent_space, ae_model in zip(latent_spaces, ae_models):\n",
    "\n",
    "    # Construct the checkpoint path for specific latent space size.\n",
    "    checkpoint_path = str.format(\"checkpoints/mnist_autoencoder_l{}_compression/cp.ckpt\", latent_space)\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=0)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(model=autoencoder_model)\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path)).expect_partial()\n",
    "\n",
    "    # The model weights (that are considered the best) are loaded into the model.\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        autoencoder_model.load_weights(checkpoint_path)\n",
    "\n",
    "    model_history = ae_model.fit(trainX, trainX,\n",
    "                                 epochs=EPOCHS,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 validation_split=0.1, shuffle=True,\n",
    "                                 verbose=1, callbacks=[cp_callback, save_images(latent_space, trainX)])\n",
    "    model_results.append(model_history)\n",
    "    autoencoder_model.save_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Result\n",
    "predictData = trainX[0:9]\n",
    "for model in ae_models:\n",
    "    result = model.predict(predictData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotCostHistories(results, loss_label=\"\", val_label=\"\", title=\"\", x_label=\"\", y_label=\"\"):\n",
    "    fig = plt.figure()\n",
    "    for result in results:\n",
    "        ax = plt.subplot(1, len(results))\n",
    "        for k, v in result.history.items():\n",
    "            plt.plot(v, label=k)\n",
    "        plt.title(label=title)\n",
    "        plt.ylabel(ylabel=y_label)\n",
    "        plt.xlabel(xlabel=x_label)\n",
    "        plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.show(block=False)\n",
    "    plt.savefig(title + \".png\")\n",
    "\n",
    "\n",
    "plotCostHistories(model_results, title=str.format(\n",
    "    \"CNN {0} Performance History\", \"Fashion\"))\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    autoencoder_model, to_file=str.format('cnn_{0}_model.png', \"Fashion\"), show_shapes=True, show_dtype=True,\n",
    "    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96,\n",
    "    layer_range=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Neuron Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in autoencoder_model:\n",
    "    ae_model = model.getModel()\n",
    "    ae_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9705cd9bb1cd3f75cacc64c830c816f4d5b8b46bb8973c8b095f871cd13babda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
