{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Compression for Stylized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q imageio pydot tensorflow-gpu==2.9.1 keras matplotlib graphviz moviepy scikit-image keras keras-tuner matplotlib kiwisolver scikit-learn tensorflow-io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras_tuner as kt\n",
    "from numpy import asarray\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os.path\n",
    "import math\n",
    "import imageio.v2 as imageio\n",
    "import glob\n",
    "from skimage.color import lab2rgb\n",
    "import PIL\n",
    "import PIL.Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_directory(data_dir, image_size, batch_size, train_size=0.8):\n",
    "    def configure_for_performance(ds, AUTOTUNE, shuffleSize):\n",
    "        #ds = ds.cache(filename='/tmp/stylizedAECache', name='stylizedAECache')\n",
    "        #ds = ds.cache()\n",
    "        if shuffleSize > 0:\n",
    "            ds = ds.shuffle(buffer_size=shuffleSize, reshuffle_each_iteration=False)\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    data_train_dir = pathlib.Path(data_dir)\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_train_dir,\n",
    "        interpolation='bilinear',\n",
    "        color_mode='rgb',\n",
    "        label_mode=None,\n",
    "        follow_links=True,\n",
    "        shuffle=False,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size)\n",
    "    #\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1.0 / 255.0)\n",
    "\n",
    "    @tf.function\n",
    "    def preprocess_lab2(img):\n",
    "        image = tf.cast(img, tf.float16)\n",
    "        lab = tfio.experimental.color.rgb_to_lab(image)\n",
    "\n",
    "        return lab\n",
    "\n",
    "    nrBatches = len(train_ds)\n",
    "\n",
    "    train_ds = configure_for_performance( train_ds, AUTOTUNE, 0)\n",
    "\n",
    "    # Translate [0,255] -> [-128, 128]\n",
    "    normalized_train_ds = (train_ds.map(lambda x: preprocess_lab2(normalization_layer(x)) * (1.0 / 128.0)))\n",
    "    normalized_expected_ds = (train_ds.map(lambda x: preprocess_lab2(normalization_layer(x)) * (1.0 / 128.0)))\n",
    "\n",
    "    # Combined train and expected data.\n",
    "    normalized_train_ds = tf.data.Dataset.zip((normalized_train_ds, normalized_expected_ds))\n",
    "    \n",
    "    final_normalized_train_ds = normalized_train_ds.take(int(train_size * nrBatches))\n",
    "    offset_skip =int(train_size * nrBatches)\n",
    "    validation_nr_batchs = int((1.0 - train_size) * nrBatches) \n",
    "    normalized_test_ds = normalized_train_ds.skip(offset_skip).take(validation_nr_batchs )\n",
    "\n",
    "    return final_normalized_train_ds, normalized_test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = (256, 256)\n",
    "EPOCHS = 24\n",
    "\n",
    "data_directory_path = \"data-stylized-compression/\"\n",
    "data_dir = pathlib.Path(data_directory_path)\n",
    "\n",
    "train_images, validation_images = load_from_directory(data_dir, IMAGE_SIZE, BATCH_SIZE, 0.8)\n",
    "\n",
    "print(\"Number of batches {0} of {1} elements\".format(\n",
    "    len(train_images), BATCH_SIZE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, expected_batch = next(iter(train_images))\n",
    "\n",
    "\n",
    "nrCol = 10\n",
    "plt.figure(figsize=(10 * 2, 12))\n",
    "for i in range(0, nrCol):\n",
    "\n",
    "    trainImage, expected = (image_batch[i % len(image_batch)], expected_batch[i % len(expected_batch)])  # (images + 1.0) / 2.0\n",
    "    trainImage = trainImage * 128.0\n",
    "    expected = expected * 128\n",
    "    # Transform pixel values from [-1,1] to [0,1]\n",
    "    LabComponet = (trainImage + 1.0) / 2.0\n",
    "\n",
    "    ax = plt.subplot(4, nrCol, nrCol * 0 + i + 1)\n",
    "    plt.imshow(LabComponet[ :, :, 0].numpy().astype(dtype='float32'), cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    ax = plt.subplot(4, nrCol, nrCol * 1 + i + 1)\n",
    "    plt.imshow(LabComponet[ :, :, 1].numpy().astype(dtype='float32'), cmap='Blues')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    ax = plt.subplot(4, nrCol, nrCol * 2 + i + 1)\n",
    "    plt.imshow(LabComponet[ :, :, 2].numpy().astype(dtype='float32'), cmap='Greens')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    ax = plt.subplot(4, nrCol, nrCol * 3 + i + 1)\n",
    "    plt.imshow(lab2rgb(expected.numpy().astype(dtype='float32')))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if len(image_batch)- 1 == i:\n",
    "        image_batch, expected_batch = next(iter(train_images))\n",
    "plt.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cnn_builder(hp, image_size):\n",
    "\n",
    "    class Autoencoder(keras.Model):\n",
    "        def __init__(self, hp, image_size, **kwargs):\n",
    "            super(Autoencoder, self).__init__(**kwargs)\n",
    "\n",
    "            kernel_init = hp.Choice('kernel_initializer', ['uniform', 'lecun_uniform', 'normal',\n",
    "                                                           'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'])\n",
    "\n",
    "            hp_kernel_filter_size_l1 = hp.Int('kernel_filter', min_value=5, max_value=8, step=1)\n",
    "            hp_kernel_size = hp.Int('kernel_size', min_value=3, max_value=4, step=1)\n",
    "            num_downscale = hp.Int('num_downscale', min_value=1, max_value=1, step=1)\n",
    "\n",
    "            number_layers = hp.Int(\n",
    "                'number_layers', min_value=2, max_value=3, step=1)\n",
    "\n",
    "            self.encoder = tf.keras.Sequential(name=\"Encoder\")\n",
    "            self.encoder.add(layers.Input(image_size))\n",
    "\n",
    "            encoder_last_conv2 = None\n",
    "            for i in range(0, number_layers + 1):\n",
    "                filter_size = 2 ** (hp_kernel_filter_size_l1 - i)\n",
    "\n",
    "                for j in range(0, num_downscale + 1):\n",
    "                    self.encoder.add(layers.Conv2D(filters=filter_size, kernel_size=hp_kernel_size,\n",
    "                                                   padding='same', strides=(2, 2), kernel_initializer=kernel_init))\n",
    "                    self.encoder.add(layers.ReLU(dtype='float32'))\n",
    "\n",
    "                encoder_last_conv2 = layers.Conv2D(filters=filter_size, kernel_size=hp_kernel_size, strides=(1, 1), padding='same', kernel_initializer=kernel_init)\n",
    "                self.encoder.add(encoder_last_conv2)\n",
    "                self.encoder.add(layers.ReLU(dtype='float32'))\n",
    "\n",
    "            # Flatten to connect tot forward neuron.\n",
    "            self.encoder.add(layers.Flatten())\n",
    "\n",
    "            # Create decoder.\n",
    "            self.decoder = tf.keras.Sequential(name=\"Decoder\")\n",
    "\n",
    "            connect_conv_shape = encoder_last_conv2.output_shape\n",
    "\n",
    "            self.decoder.add(layers.Reshape(target_shape=(\n",
    "                connect_conv_shape[1], connect_conv_shape[2], connect_conv_shape[3])))\n",
    "\n",
    "            for i in range(0, number_layers + 1):\n",
    "                filter_size = 2 ** ((hp_kernel_filter_size_l1 - number_layers) + i)\n",
    "\n",
    "                self.decoder.add(layers.Conv2D(filters=filter_size, kernel_size=hp_kernel_size, strides=(1, 1), padding='same', kernel_initializer=kernel_init))\n",
    "                self.decoder.add(layers.ReLU(dtype='float32'))\n",
    "\n",
    "                for j in range(0, num_downscale + 1):\n",
    "                    self.decoder.add(layers.Conv2D(filters=filter_size, kernel_size=hp_kernel_size,\n",
    "                                                            padding='same', strides=(1, 1), kernel_initializer=kernel_init))\n",
    "                    self.decoder.add(layers.ReLU(dtype='float32'))\n",
    "                    self.decoder.add(layers.UpSampling2D(size=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "            self.decoder.add(layers.Conv2D(filters=3, kernel_size=(3, 3), padding='same', kernel_initializer=kernel_init))\n",
    "            self.decoder.add(layers.Activation(activation='tanh', dtype='float32'))\n",
    "\n",
    "\n",
    "\n",
    "        def load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None):\n",
    "            self.encoded.load_weights(filepath+'encode', by_name, skip_mismatch, options)\n",
    "            self.decoded.load_weights(filepath+'decode', by_name, skip_mismatch, options)\n",
    "\n",
    "        def save_weights(self, filepath, overwrite=True, save_format=None, options=None):\n",
    "            self.encoded.save_weights(filepath+'encode', overwrite, save_format, options)\n",
    "            self.decoded.save_weights(filepath+'decode', overwrite, save_format, options)\n",
    "\n",
    "        def getEncoder(self):\n",
    "            return self.encoder\n",
    "\n",
    "        def getLatentSpace(self):\n",
    "            return self.latentspace\n",
    "\n",
    "        def getDecoder(self):\n",
    "            return self.decoder\n",
    "\n",
    "        def compile(self, optimizer, **kwargs):\n",
    "            super(Autoencoder, self).compile(**kwargs)\n",
    "            self.optimizer = optimizer\n",
    "\n",
    "        def summary(self, **kwargs):\n",
    "            super(Autoencoder, self).summary(**kwargs)\n",
    "            self.encoder.summary()\n",
    "            self.decode.summary()\n",
    "\n",
    "    autoencoder = Autoencoder(hp, image_size)\n",
    "\n",
    "    hp_optimizer = hp.Choice('optimizer', ['sgd', 'adam', 'adadelta'])\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[2e-3, 2e-4, 5e-4])\n",
    "    optimizer = tf.keras.optimizers.get(hp_optimizer)\n",
    "    optimizer.learning_rate = hp_learning_rate\n",
    "\n",
    "    ae_input = layers.Input(shape=image_size, name=\"AE_input\")\n",
    "    ae_encoder_output = autoencoder.encoder(ae_input)\n",
    "    ae_decoder_output = autoencoder.decoder(ae_encoder_output)\n",
    "\n",
    "    conv_autoencoder = keras.Model(inputs=ae_input, outputs=ae_decoder_output)\n",
    "\n",
    "    conv_autoencoder.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
    "    # Present the model.\n",
    "    conv_autoencoder.summary()\n",
    "    conv_autoencoder.layers[1].summary()\n",
    "    conv_autoencoder.layers[2].summary()\n",
    "\n",
    "    return conv_autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_shape = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    "print('Train Image Size: ' + str(image_shape))\n",
    "\n",
    "\n",
    "def hyperparamter_model_builder(hp):\n",
    "    model = generate_cnn_builder(hp, image_shape)\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(hyperparamter_model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=20,\n",
    "                     factor=4,\n",
    "                     directory='cache',\n",
    "                     project_name=str.format('Stylized AutoEncoder - {0}', \"Compression\"))\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=2)\n",
    "\n",
    "tuner.search(train_images, epochs=EPOCHS,\n",
    "             validation_data=validation_images,\n",
    "             callbacks=[stop_early, tf.keras.callbacks.TerminateOnNaN()], verbose=1)\n",
    "\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "autoencoder_model = tuner.hypermodel.build(best_hps)\n",
    "autoencoder_model.summary()\n",
    "autoencoder_model.layers[1].summary()\n",
    "autoencoder_model.layers[2].summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResult(model, batchImage, maxNumImages=6):\n",
    "    output = model.predict(batchImage)\n",
    "    output = output * 128\n",
    "    nrElements = min(len(output), maxNumImages)\n",
    "    image_batch, _ = next(iter(train_images))\n",
    "\n",
    "    fig = plt.figure(figsize=(maxNumImages * 2, 5 * 2))\n",
    "    for i in range(nrElements):\n",
    "\n",
    "        ax = plt.subplot(5, maxNumImages, i + 1)\n",
    "        plt.imshow((asarray(lab2rgb(image_batch[i] * 128)).astype(dtype='float32')))\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        ax = plt.subplot(5, maxNumImages, maxNumImages * 1 + i + 1)\n",
    "        plt.imshow(output[i, :, :, 0]  , cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        ax = plt.subplot(5, maxNumImages, maxNumImages * 2 + i + 1)\n",
    "        plt.imshow(output[i, :, :, 1], cmap='Blues')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        ax = plt.subplot(5, maxNumImages, maxNumImages * 3 + i + 1)\n",
    "        plt.imshow(output[i, :, :, 2], cmap='Greens')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        ax = plt.subplot(5, maxNumImages, maxNumImages * 4 + 1 + i)\n",
    "        plt.imshow(asarray(lab2rgb(output[i])).astype(dtype='float32'))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        if len(image_batch)- 1 == i:\n",
    "            image_batch, expected_batch = next(iter(train_images))\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "\n",
    "class save_images(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, trainData, **kwargs):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__(**kwargs)\n",
    "        self.trainSet = trainData.take(1)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        fig = showResult(self.model, self.trainSet)\n",
    "        fig.savefig(\"StylizedCompression{0}.png\".format(epoch))\n",
    "        fig = showResult(self.model, self.trainSet, 12)\n",
    "        fig.savefig(\"StylizedCompressionBig{0}.png\".format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"checkpoints/training_stylized_compression/cp.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=0)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(model=autoencoder_model)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path)).expect_partial()\n",
    "\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "if os.path.exists(checkpoint_path):\n",
    "    autoencoder_model.load_weights(checkpoint_path)\n",
    "    \n",
    "autoencoder_history = autoencoder_model.fit(train_images,\n",
    "                      epochs=EPOCHS,\n",
    "                      shuffle=True,\n",
    "                      validation_data=validation_images, callbacks=[cp_callback, save_images(train_images)])\n",
    "autoencoder_model.save_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model.save(\"stylized-ae-compression.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "The result is both in how good the model reconstruct as well how much of a compression ratio it would yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evolution\n",
    "result = autoencoder_model.evaluate(validation_images, batch_size=BATCH_SIZE)\n",
    "print(result)\n",
    "\n",
    "\n",
    "latent_space_size = autoencoder_model.layers[1].output_shape[1]\n",
    "print(\"Latent Space {0}\", latent_space_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCostHistory(history, loss_label=\"\", val_label=\"\", title=\"\", x_label=\"\", y_label=\"\"):\n",
    "    fig = plt.figure()\n",
    "    for k, v in history.items():\n",
    "        plt.plot(v, label=k)\n",
    "    plt.title(label=title)\n",
    "    plt.ylabel(ylabel=y_label)\n",
    "    plt.xlabel(xlabel=x_label)\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    fig.show()\n",
    "    fig.savefig(title + \".png\")\n",
    "\n",
    "\n",
    "plotCostHistory(autoencoder_history.history, title=str.format(\n",
    "    \"{0} Performance History\", \"Stylized Colorization\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.figure(1,1)\n",
    "fig, ax = plt.subplots(figsize=(18, 5))\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(plt.imread(\"StylizedCompressionBig{0}.png\".format(EPOCHS - 1)))\n",
    "plt.title('Final Result', \n",
    "                                     fontweight =\"bold\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression Ratio\n",
    "Since the purpose of dimmension reduction is for creating a lossy compression that hopefully has a low size than either jpg/png. In respect to the level lossy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode Improvement Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'stylized-compression.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('StylizedCompressionBig*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "Image(url=anim_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(zs, steps):\n",
    "    out = []\n",
    "    for i in range(len(zs)-1):\n",
    "        for index in range(steps):\n",
    "            fraction = index/float(steps)\n",
    "            out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present LatentSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import moviepy.editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transition(model, latent_space, grid_size):\n",
    "      nr_elemenets = 4\n",
    "      seeds = np.random.randint(10000, size=2)\n",
    "      zs = [tf.random.normal([nr_elemenets, latent_space_size], seed=s)\n",
    "            for s in seeds]\n",
    "      \n",
    "      all_latents = interpolate(zs, nr_elemenets)\n",
    "\n",
    "      generated_images = model(latent_space, training=False)\n",
    "\n",
    "      fig = plt.figure(figsize=(grid_size[0] * 2, grid_size[1] * 2))\n",
    "      for i in range(generated_images.shape[0]):\n",
    "            plt.subplot(grid_size[0], grid_size[1], i+1,)\n",
    "\n",
    "            plt.imshow(((generated_images[i, :, :, :] + 1.0) / 2.0), aspect='auto')\n",
    "            plt.axis(\"off\")\n",
    "      plt.subplots_adjust(wspace=0, hspace=0)\n",
    "      plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid_image(model, latent_space, figsize=(8, 8), subplotsize=(3, 3)):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(latent_space, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(subplotsize[0], subplotsize[1], i + 1)\n",
    "        rgb = (predictions[i, :, :, 0:3] + 1.0) / 2.0\n",
    "        plt.imshow(asarray(rgb))\n",
    "        plt.axis('off')\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fps = 15\n",
    "duration_sec = 5\n",
    "smoothing_sec = 1.0\n",
    "num_frames = 4 * fps\n",
    "\n",
    "shape = [num_frames, np.prod(latent_space_size)]\n",
    "\n",
    "nr_elemenets = 16\n",
    "\n",
    "seeds = np.random.randint(10000, size=2)\n",
    "zs = [tf.random.normal([nr_elemenets, latent_space_size], seed=s)\n",
    "      for s in seeds]\n",
    "\n",
    "all_latents = interpolate(zs, num_frames)\n",
    "\n",
    "\n",
    "def make_frame(t):\n",
    "    frame_idx = int(np.clip(np.round(t * fps), 0, num_frames - 1))\n",
    "    latents = all_latents[frame_idx]\n",
    "\n",
    "    # Generate figure in respect new latent pace \n",
    "    fig = generate_grid_image(autoencoder_model.layers[2], latents, (5, 5), (4, 4))\n",
    "\n",
    "    # Convert figure to bitmap.\n",
    "    fig.canvas.draw()\n",
    "    data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "gif_filepath = ('autoencoder_stylized_compression_transition_grid_{0}.gif'.format(seeds[0]))\n",
    "video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
    "video_clip.write_gif(gif_filepath, fps=fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=gif_filepath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9705cd9bb1cd3f75cacc64c830c816f4d5b8b46bb8973c8b095f871cd13babda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
