{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import ImageFilter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_face_dataset(resize=(96, 96), path=\"./faces\"):\n",
    "    cacheFileX = \"cacheX.sav\"\n",
    "    cacheFileY = \"cacheY.sav\"\n",
    "\n",
    "    try:\n",
    "        with open(cacheFileX, 'rb') as f:\n",
    "            X = pickle.loads(f.read())\n",
    "        with open(cacheFileY, 'rb') as f:\n",
    "            y = pickle.loads(f.read())\n",
    "    except FileNotFoundError as f:\n",
    "        # Load data\n",
    "        X = []\n",
    "        y = []\n",
    "        for characterName in os.listdir(path):\n",
    "            charNamePath = \"{}/{}\".format(path, characterName)\n",
    "            if os.path.isdir(charNamePath):\n",
    "                for imagePaths in os.listdir(charNamePath):\n",
    "                    finalImagePath = \"{}/{}\".format(charNamePath, imagePaths)\n",
    "                    img = Image.open(finalImagePath).convert(\n",
    "                        'L').filter(ImageFilter.FIND_EDGES)\n",
    "                    NPX = np.array(img)\n",
    "                    X.append(NPX.reshape(96 * 96))\n",
    "                    y.append(characterName)\n",
    "\n",
    "        with open(cacheFileX, 'wb') as f:\n",
    "            pickle.dump(X, f)\n",
    "        with open(cacheFileY, 'wb') as f:\n",
    "            pickle.dump(y, f)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = load_face_dataset()  # load_dataset(NrChar=4,nSamples=1000)\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "yhot = onehot_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process the features values.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "nX = scaler.fit_transform(X)\n",
    "print(\"scalar mean\", scaler.mean_)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    nX, yhot, test_size=0.2, shuffle=True)\n",
    "parameters = {'activation': ['logistic', 'relu'], 'alpha': [1e-5, 1e-4, 1e-2, 1e-1], 'solver': ['sgd'],\n",
    "              'hidden_layer_sizes': [(10, 30, 20), (100, 50, 10), (20, 30), (15, 10), (10, 15), (10, 10)]}\n",
    "\n",
    "plt.figure(figsize=(40, 5))\n",
    "nSamples = 20\n",
    "for index, (image, label) in enumerate(zip(x_train[0:nSamples], y_train[0:nSamples])):\n",
    "    plt.subplot(nSamples / 5, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (96, 96)), cmap=plt.cm.gray)\n",
    "    hotName = onehot_encoder.inverse_transform([label])\n",
    "\n",
    "    nameIndex = int(hotName[0])\n",
    "    name = label_encoder.inverse_transform([nameIndex])[0]\n",
    "    plt.title('{}'.format(name), fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "clf = MLPClassifier()\n",
    "grid = GridSearchCV(clf, param_grid=parameters, cv=10, n_jobs=7)\n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.score(x_test, y_test))\n",
    "bestModel = grid.best_estimator_\n",
    "print(bestModel)\n",
    "\n",
    "# Save the model.\n",
    "modelPath = \"exec5_model.sav\"\n",
    "with open(modelPath, 'wb') as f:\n",
    "    pickle.dump(bestModel, f)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
