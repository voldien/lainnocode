{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import style\n",
    "\n",
    "from regression import logisticCost, \\\n",
    "    Sigmod, linear, extendMatrix, logisticGradient\n",
    "from statistics import normalizeFeature, deviation\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "colorSet = ['r', 'b']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('admission.csv', header=None)\n",
    "\n",
    "X = np.array(df.drop(columns=2, axis=1).T)\n",
    "y = np.array(df.loc[:, 2])\n",
    "\n",
    "normalX = np.array(normalizeFeature(X))\n",
    "normalY = np.array(normalizeFeature([y]))\n",
    "\n",
    "for i, x in enumerate(normalX):\n",
    "    print(\"nth\", i, \"deviation:\", deviation(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot normalized\n",
    "for x in normalX:\n",
    "    for x_, _y in zip(x, y):\n",
    "        plt.scatter(x_, _y, color=colorSet[_y])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use sigmod matrix.\n",
    "m = [[0, 1, ], [2, 3]]\n",
    "sig = Sigmod(m)\n",
    "print(sig)\n",
    "\n",
    "# Create Extended X matrix.\n",
    "Xe = extendMatrix([x for x in normalX])\n",
    "\n",
    "# logistic cost function\n",
    "testBeta = np.array([0, 0, 0])\n",
    "cost = logisticCost(Xe, testBeta, y, linear)\n",
    "print(\"expected cost : {}, computed cost {}\".format(0.6931, cost))\n",
    "\n",
    "# Simple gradient descent\n",
    "beta = logisticGradient(Xe, testBeta, y, 0.5, 1)\n",
    "cost = logisticCost(Xe, beta, y, linear)\n",
    "expectedBeta = [0.05, 0.141, 0.125]\n",
    "print(\"expected beta : {}, computed beta {}\".format(expectedBeta, beta.tolist()))\n",
    "\n",
    "# gradient descent\n",
    "alpha = 0.2035\n",
    "for n in range(10, 10000, 500):\n",
    "    optimized = logisticGradient(Xe, testBeta, y, alpha, n)\n",
    "\n",
    "    combinationCost = logisticCost(Xe, optimized, y, linear)\n",
    "\n",
    "    print(\"alpha {}, iterations: {} cost : {}\".format(\n",
    "        float(alpha), n, round(combinationCost, 10)))\n",
    "\n",
    "# gradient descent\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
