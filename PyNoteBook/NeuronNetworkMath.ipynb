{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Forward Neuron Network\n",
    "A simple forward network for computing binary math operations. Where two Neurons are the decimal input, and the third is the math operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q imageio pydot tensorflow-gpu==2.9.3 keras matplotlib graphviz moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/programming/projects/machineLearning/ML/venv/lib/python3.8/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Flatten\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU, ReLU\n",
    "from random import Random\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Output Directory\n",
    "Set the output directory where all the results will be storaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"result/forward_math_neuron network\"\n",
    "if not os.path.exists(root_dir):\n",
    "    os.mkdir(root_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all Modules and Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 10:31:06.367573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-21 10:31:06.390889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-21 10:31:06.391083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-21 10:31:06.392278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-21 10:31:06.393548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-21 10:31:06.393696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-21 10:31:06.393813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-21 10:31:06.801887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-21 10:31:06.802047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-21 10:31:06.802156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-21 10:31:06.802247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6099 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" # Debug only\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # mixed_precision.set_global_policy('mixed_float16')\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Initialize tf.distribute.MirroredStrategy\n",
    "strategy = tf.distribute.MirroredStrategy(devices=None)\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_number_set(size):\n",
    "\tnumber_Y = []\n",
    "\tnumber_X = []\n",
    "\trandom = Random()\n",
    "\tfor i in range(0, size):\n",
    "\t\ta = random.random() * 100\n",
    "\t\tb = random.random() * 100\n",
    "\t\tmath_operator = float(random.randint(0, 2))\n",
    "\n",
    "\t\tnumber_X.append([a, b, math_operator])\n",
    "\n",
    "\t\tif math_operator == 0:\n",
    "\t\t\tnumber_Y.append(a + b)\n",
    "\t\telif math_operator == 1:\n",
    "\t\t\tnumber_Y.append(a - b)\n",
    "\t\telif math_operator == 2:\n",
    "\t\t\tnumber_Y.append(a * b)\n",
    "#        elif math_operator == 3:\n",
    "#            number_Y.append(a / b)\n",
    "\n",
    "\treturn numpy.asarray(number_X), np.asarray(number_Y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generator with Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_generator_model(hp, input, output):\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\tkernel_init = hp.Choice('kernel_initializer', ['uniform', 'lecun_uniform', 'normal', 'zero',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'])\n",
    "\n",
    "\thp0_units = hp.Int('dense0_units', min_value=32, max_value=512, step=32)\n",
    "\thp1_units = hp.Int('dense1_units', min_value=32, max_value=512, step=32)\n",
    "\thp2_units = hp.Int('dense2_units', min_value=32, max_value=512, step=32)\n",
    "\n",
    "\tmodel.add(Dense(hp0_units, input_dim=input, kernel_initializer=kernel_init, dtype='float32'))\n",
    "\tmodel.add(ReLU())\n",
    "\tmodel.add(Dense(hp1_units, dtype='float32', kernel_initializer=kernel_init))\n",
    "\tmodel.add(ReLU())\n",
    "\tmodel.add(Dense(hp2_units, dtype='float32', kernel_initializer=kernel_init))\n",
    "\tmodel.add(ReLU())\n",
    "\tmodel.add(Dense(output, dtype='float32', kernel_initializer=kernel_init))\n",
    "\n",
    "\thp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-1])\n",
    "\n",
    "\thp_optimizer = hp.Choice('optimizer', ['sgd', 'adam', 'rmsprop'])\n",
    "\n",
    "\toptimizer = tf.keras.optimizers.get(hp_optimizer)\n",
    "\toptimizer.learning_rate = hp_learning_rate\n",
    "\n",
    "\tdef ssim_loss(y_true, y_pred):\n",
    "\t\treturn (tf.reduce_mean(y_true - y_pred , axis=-1))\n",
    "\n",
    "\tmodel.compile(optimizer=optimizer,\n",
    "\t\t\t\t\tloss='mae',\n",
    "\t\t\t\t\tmetrics=['accuracy'])\n",
    "\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 Complete [00h 00m 08s]\n",
      "val_accuracy: 0.0\n",
      "\n",
      "Best val_accuracy So Far: 0.0\n",
      "Total elapsed time: 00h 07m 42s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 96)                384       \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 96)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               12416     \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 480)               61920     \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 480)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 481       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,201\n",
      "Trainable params: 75,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/64\n",
      "1000/1000 [==============================] - 2s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 22/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 23/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 24/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 25/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 26/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 27/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 28/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 29/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 30/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 31/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 32/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 33/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 34/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 35/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 36/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 37/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 38/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 39/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 40/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 41/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 42/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 43/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 44/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 45/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 46/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 47/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 48/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 49/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 50/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 51/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 52/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 53/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 54/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 55/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 56/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 57/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 58/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 59/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 60/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 61/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 62/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 63/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 64/64\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "input = 3\n",
    "output = 1\n",
    "EPOCH = 64\n",
    "BATCH_SIZE = 4096\n",
    "train_X, train_y = generate_number_set(5120000)\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = make_generator_model(hp, input, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=48,\n",
    "                     factor=4,\n",
    "                     directory=os.path.join(root_dir, 'cache'),\n",
    "                     project_name=str.format('Math'))\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(train_X, train_y, epochs=50, batch_size=BATCH_SIZE, validation_split=0.25, callbacks=[stop_early, tf.keras.callbacks.TerminateOnNaN()])\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "best_models = tuner.get_best_models(8)\n",
    "\n",
    "train_X, train_y = generate_number_set(5120000)\n",
    "\n",
    "cnn_model = tuner.hypermodel.build(best_hps)\n",
    "cnn_model.summary()\n",
    "cnn_model_history = cnn_model.fit(train_X, train_y, batch_size=BATCH_SIZE, epochs=EPOCH, validation_split=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9705cd9bb1cd3f75cacc64c830c816f4d5b8b46bb8973c8b095f871cd13babda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
