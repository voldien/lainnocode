{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q imageio pydot tensorflow-gpu==2.9.1 keras matplotlib graphviz moviepy scikit-image keras keras-tuner matplotlib kiwisolver scikit-learn tensorflow-io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras_tuner as kt\n",
    "from numpy import asarray\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os.path\n",
    "import math\n",
    "import imageio.v2 as imageio\n",
    "import glob\n",
    "from skimage.color import lab2rgb\n",
    "import PIL\n",
    "import PIL.Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # mixed_precision.set_global_policy('mixed_float16')\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_directory(data_dir, train_subdir, test_subdir, image_size, batch_size, train_size=0.8):\n",
    "    def configure_for_performance(ds, AUTOTUNE, shuffleSize):\n",
    "        ds = ds.cache()\n",
    "        if shuffleSize > 0:\n",
    "            ds = ds.shuffle(buffer_size=shuffleSize, reshuffle_each_iteration=False)\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    data_train_dir = pathlib.Path(data_dir.as_posix() + \"/\" + train_subdir)\n",
    "    image_count = len(list(data_train_dir.glob('**/*.??g')))\n",
    "    print(\"{0}: Found {1} files\".format(data_train_dir, image_count))\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_train_dir,\n",
    "        interpolation='bilinear',\n",
    "        color_mode='rgb',\n",
    "        label_mode=None,\n",
    "        follow_links=True,\n",
    "        shuffle=False,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    #\n",
    "    data_test_dir = pathlib.Path(data_dir.as_posix() + \"/\" + test_subdir)\n",
    "    image_count = len(list(data_test_dir.glob('**/*.??g')))\n",
    "    print(\"{0}: Found {1} files\".format(data_test_dir, image_count))\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_test_dir,\n",
    "        interpolation='bilinear',\n",
    "        color_mode='rgb',\n",
    "        label_mode=None,\n",
    "        follow_links=True,\n",
    "        shuffle=False,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    #\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1.0 / 255.0)\n",
    "\n",
    "    @tf.function\n",
    "    def preprocess_lab(img):\n",
    "        image = tf.cast(img, tf.float32)\n",
    "\n",
    "        lab = tfio.experimental.color.rgb_to_lab(image)\n",
    "        l = lab[..., 0]\n",
    "\n",
    "        l = tf.expand_dims(l, axis=-1)\n",
    "        return tf.cast(tf.concat(l, axis=-1), tf.float32)\n",
    "\n",
    "    @tf.function\n",
    "    def preprocess_lab2(img):\n",
    "        image = tf.cast(img, tf.float32)\n",
    "        lab = tfio.experimental.color.rgb_to_lab(image)\n",
    "        a = lab[..., 1]\n",
    "        b = lab[..., 2]\n",
    "\n",
    "        a = tf.expand_dims(a, axis=-1)\n",
    "        b = tf.expand_dims(b, axis=-1)\n",
    "        return tf.cast(tf.concat([a, b], axis=-1), tf.float32)\n",
    "\n",
    "    nrBatches = image_count / batch_size\n",
    "\n",
    "    # Translate [0,255] -> [-128, 128]\n",
    "    normalized_train_ds = (train_ds.map(lambda x: preprocess_lab(normalization_layer(x))))\n",
    "\n",
    "    # Translate [0,255] -> [-1, 1]\n",
    "    normalized_test_ds = (test_ds.map(lambda x: (preprocess_lab2(normalization_layer(x)) * (1.0 / 128.0))))\n",
    "\n",
    "    train_ds = tf.data.Dataset.zip((normalized_train_ds, normalized_test_ds))\n",
    "    train_ds = train_ds.take(int(train_size * nrBatches))\n",
    "    test_ds = train_ds.skip(int(train_size * nrBatches)).take(int((1.0 - train_size) * nrBatches))\n",
    "\n",
    "    return configure_for_performance(train_ds, AUTOTUNE, 0), configure_for_performance(test_ds, AUTOTUNE, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "IMAGE_SIZE = (256, 256)\n",
    "EPOCHS = 64\n",
    "\n",
    "data_directory_path = \"data-colorize/\"\n",
    "data_dir = pathlib.Path(data_directory_path)\n",
    "\n",
    "train_images, test_images = load_from_directory(data_dir, \"\", \"\", IMAGE_SIZE, BATCH_SIZE, 0.85)\n",
    "\n",
    "print(\"Number of batches {0} of {1} elements\".format(\n",
    "    len(train_images), BATCH_SIZE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_to_generate = 9\n",
    "\n",
    "nrCol = 5\n",
    "plt.figure(figsize=(10 * 2, 12))\n",
    "for images in train_images.take(1):\n",
    "    for i in range(0, 5):\n",
    "\n",
    "        trainImage, expectedImage = images\n",
    "        # Transform pixel values from [-1,1] to [0,1]\n",
    "        trainLAB = trainImage[i, :, :].numpy().astype(dtype='float32')\n",
    "\n",
    "        ax = plt.subplot(4, nrCol, nrCol * 0 + i + 1)\n",
    "        plt.imshow(trainLAB, cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        ax = plt.subplot(4, nrCol, nrCol * 1 + i + 1)\n",
    "        plt.imshow(expectedImage[i, :, :, 0], cmap='Blues')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        ax = plt.subplot(4, nrCol, nrCol * 2 + i + 1)\n",
    "        plt.imshow(expectedImage[i, :, :, 1], cmap='Greens')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        expectedImage = expectedImage[i, :, :, :].numpy().astype(dtype='float32') * 128\n",
    "        RGBImage = np.zeros((IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "        RGBImage[:, :, 0] = trainLAB[:, :, 0]\n",
    "        RGBImage[:, :, 1:] = expectedImage\n",
    "\n",
    "        rgbExpected = lab2rgb(RGBImage)\n",
    "\n",
    "        ax = plt.subplot(4, nrCol, nrCol * 3 + i + 1)\n",
    "        plt.imshow(rgbExpected)\n",
    "        plt.axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp, input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    init = tf.keras.initializers.TruncatedNormal(stddev=0.02)\n",
    "\n",
    "    kernel_init = hp.Choice('kernel_initializer', ['uniform', 'lecun_uniform', 'normal', 'zero',\n",
    "                                                   'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'])\n",
    "\n",
    "    model.add(layers.Input(input_shape))\n",
    "\n",
    "    number_layer_offset = hp.Int('number_layers', min_value=2, max_value=6, step=1)\n",
    "    max_layers = 3\n",
    "\n",
    "    n2 = math.log2(float(IMAGE_SIZE[0]))\n",
    "    num_layers = max(int(n2) - number_layer_offset, 0)\n",
    "    num_layers = max(1, min(num_layers, max_layers))\n",
    "\n",
    "    hp_kernel_filter_size_l0 = hp.Int('kernel_filter_downscale', min_value=4, max_value=8, step=1)\n",
    "\n",
    "    for i in range(0, num_layers + 1):\n",
    "        filter_size = 2 ** (i + hp_kernel_filter_size_l0)\n",
    "\n",
    "        #model.add(layers.Conv2D(filter_size, (3, 3), activation='relu', padding='same', kernel_initializer=kernel_init))\n",
    "\n",
    "        model.add(layers.Conv2D(filter_size, (3, 3), activation='relu', padding='same', kernel_initializer=kernel_init))\n",
    "\n",
    "        model.add(layers.Conv2D(filter_size, (3, 3), activation='relu', padding='same', strides=2))\n",
    "        #model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # model.add(layers.Flatten())\n",
    "    hp_kernel_filter_size_latent = hp.Int('kernel_filter_latent', min_value=6, max_value=9, step=1)\n",
    "    model.add(layers.Conv2D(2 ** hp_kernel_filter_size_latent, (3, 3), activation='relu', padding='same', kernel_initializer=kernel_init))\n",
    "    model.add(layers.Conv2D(2 ** (hp_kernel_filter_size_latent - 1), (3, 3), activation='relu', padding='same', kernel_initializer=kernel_init))\n",
    "\n",
    "    hp_kernel_filter_size_l1 = hp.Int('kernel_filter_upscale', min_value=5, max_value=9, step=1)\n",
    "\n",
    "    #upscale_number_layer_offset = hp.Int('upscale_number_layer_offset', min_value=4, max_value=6, step=1)\n",
    "\n",
    "    for i in range(0, num_layers + 1):\n",
    "        filter_size = 2 ** (hp_kernel_filter_size_l1 - i)\n",
    "\n",
    "        #model.add(layers.Conv2D(filter_size, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n",
    "        #model.add(layers.Conv2D(filter_size, (3, 3), activation='relu', padding='same', kernel_initializer=kernel_init))\n",
    "        model.add(layers.UpSampling2D(size=(2, 2)))\n",
    "        model.add(layers.Conv2D(filter_size, (3, 3), activation='relu', padding='same', kernel_initializer=kernel_init))\n",
    "\n",
    "    model.add(layers.Conv2D(2, (3, 3), activation='tanh', padding='same', kernel_initializer=kernel_init))\n",
    "\n",
    "    hp_optimizer = hp.Choice('optimizer', ['sgd', 'adam', 'rmsprop'])\n",
    "\n",
    "    model.compile(optimizer=hp_optimizer,\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_shape = (IMAGE_SIZE[0], IMAGE_SIZE[1], 1)\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = create_model(hp, image_shape)\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='accuracy',\n",
    "                     max_epochs=16,\n",
    "                     factor=5,\n",
    "                     directory='cache',\n",
    "                     project_name=str.format('Colorizing - LAB - {0}', \"Anime\"))\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', patience=5)\n",
    "tuner.search(train_images.take(1000), validation_data=test_images, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "             callbacks=[stop_early], verbose=1)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_models = tuner.get_best_models(4)\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
