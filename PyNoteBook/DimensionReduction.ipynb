{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimention Reudction\n",
    "PCA, ICA, T-SNE, Sammon, Auto-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        mixed_precision.set_global_policy('mixed_float16')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFashion():\n",
    "    (train_images, train_labels), (test_images, test_labels) = tensorflow.keras.datasets.fashion_mnist.load_data()\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "    TrainX = np.concatenate((train_images, test_images))\n",
    "    TrainY = np.squeeze(np.concatenate((train_labels, test_labels)))\n",
    "    TrainX = 2.0 * (TrainX / 255.0) - 1.0\n",
    "    TrainX = np.expand_dims(TrainX, axis=-1)  # <--- add batch axis\n",
    "\n",
    "    return TrainX, TrainY, class_names\n",
    "\n",
    "def loadDataCifar10():\n",
    "    (train_images, train_labels), (test_images, test_labels) = tensorflow.keras.datasets.cifar10.load_data()\n",
    "    class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"ship\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "    TrainX = np.concatenate((train_images, test_images))\n",
    "    TrainY = np.squeeze(np.concatenate((train_labels, test_labels)))\n",
    "    # Normalize into [0,1], as float32\n",
    "    TrainX = TrainX / 255.0\n",
    "\n",
    "    return TrainX, TrainY, class_names\n",
    "\n",
    "def loadDataCifar100():\n",
    "    (train_images, train_labels), (test_images,\n",
    "                                   test_labels) = tensorflow.keras.datasets.cifar100.load_data(label_mode='fine'\n",
    "                                                                                               )\n",
    "\n",
    "    class_names = [\n",
    "        \"apple\",\n",
    "        \"aquarium_fish\",\n",
    "        \"baby\",\n",
    "        \"bear\",\n",
    "        \"beaver\",\n",
    "        \"bed\",\n",
    "        \"bee\",\n",
    "        \"beetle\",\n",
    "        \"bicycle\",\n",
    "        \"bottle\",\n",
    "        \"bowl\",\n",
    "        \"boy\",\n",
    "        \"bridge\",\n",
    "        \"bus\",\n",
    "        \"butterfly\",\n",
    "        \"camel\",\n",
    "        \"can\",\n",
    "        \"castle\",\n",
    "        \"caterpillar\",\n",
    "        \"cattle\",\n",
    "        \"chair\",\n",
    "        \"chimpanzee\",\n",
    "        \"clock\",\n",
    "        \"cloud\",\n",
    "        \"cockroach\",\n",
    "        \"couch\",\n",
    "        \"crab\",\n",
    "        \"crocodile\",\n",
    "        \"cup\",\n",
    "        \"dinosaur\",\n",
    "        \"dolphin\",\n",
    "        \"elephant\",\n",
    "        \"flatfish\",\n",
    "        \"forest\",\n",
    "        \"fox\",\n",
    "        \"girl\",\n",
    "        \"hamster\",\n",
    "        \"house\",\n",
    "        \"kangaroo\",\n",
    "        \"keyboard\",\n",
    "        \"lamp\",\n",
    "        \"lawn_mower\",\n",
    "        \"leopard\",\n",
    "        \"lion\",\n",
    "        \"lizard\",\n",
    "        \"lobster\",\n",
    "        \"man\",\n",
    "        \"maple_tree\",\n",
    "        \"motorcycle\",\n",
    "        \"mountain\",\n",
    "        \"mouse\",\n",
    "        \"mushroom\",\n",
    "        \"oak_tree\",\n",
    "        \"orange\",\n",
    "        \"orchid\",\n",
    "        \"otter\",\n",
    "        \"palm_tree\",\n",
    "        \"pear\",\n",
    "        \"pickup_truck\",\n",
    "        \"pine_tree\",\n",
    "        \"plain\",\n",
    "        \"plate\",\n",
    "        \"poppy\",\n",
    "        \"porcupine\",\n",
    "        \"possum\",\n",
    "        \"rabbit\",\n",
    "        \"raccoon\",\n",
    "        \"ray\",\n",
    "        \"road\",\n",
    "        \"rocket\",\n",
    "        \"rose\",\n",
    "        \"sea\",\n",
    "        \"seal\",\n",
    "        \"shark\",\n",
    "        \"shrew\",\n",
    "        \"skunk\",\n",
    "        \"skyscraper\",\n",
    "        \"snail\",\n",
    "        \"snake\",\n",
    "        \"spider\",\n",
    "        \"squirrel\",\n",
    "        \"streetcar\",\n",
    "        \"sunflower\",\n",
    "        \"sweet_pepper\",\n",
    "        \"table\",\n",
    "        \"tank\",\n",
    "        \"telephone\",\n",
    "        \"television\",\n",
    "        \"tiger\",\n",
    "        \"tractor\",\n",
    "        \"train\",\n",
    "        \"trout\",\n",
    "        \"tulip\",\n",
    "        \"turtle\",\n",
    "        \"wardrobe\",\n",
    "        \"whale\",\n",
    "        \"willow_tree\",\n",
    "        \"wolf\",\n",
    "        \"woman\",\n",
    "        \"worm\"]\n",
    "\n",
    "    TrainX = np.concatenate((train_images, test_images))\n",
    "    TrainY = np.squeeze(np.concatenate((train_labels, test_labels)))\n",
    "\n",
    "    TrainX = TrainX / 255.0\n",
    "\n",
    "    return TrainX, TrainY, class_names\n",
    "\n",
    "\n",
    "def loadDataFlower(image_size, batch_size):\n",
    "    def configure_for_performance(ds, AUTOTUNE):\n",
    "        ds = ds.cache()\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "    data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                       fname='flower_photos',\n",
    "                                       cache_dir='.',\n",
    "                                       untar=True)\n",
    "    data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "    # Search and find number of elements within directory, recursively.\n",
    "    image_count = len(list(data_dir.glob('**/*.??g')))\n",
    "    print(\"{0}: Found {1} files\".format(data_dir, image_count))\n",
    "\n",
    "    #\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        interpolation='bilinear',\n",
    "        color_mode='rgb',\n",
    "        follow_links=True,\n",
    "        shuffle=True,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "    #\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1. / 255.0)\n",
    "\n",
    "    # Translate [0,255] -> [-1, 1]\n",
    "    normalized_ds = configure_for_performance(train_ds.map(lambda x, y: (normalization_layer(x) * 2.0 - 1.0, y)),\n",
    "                                              AUTOTUNE)\n",
    "\n",
    "    return normalized_ds, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FashionX, FashionY, labels = loadDataFashion()\n",
    "Cifar10X, Cifar10Y, labels = loadDataCifar10()\n",
    "Cifar100X, Cifar100Y, labels = loadDataCifar100()\n",
    "FlowerX, FlowerY, labels = loadDataFlower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sammon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9705cd9bb1cd3f75cacc64c830c816f4d5b8b46bb8973c8b095f871cd13babda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
